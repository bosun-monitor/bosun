################################################ Basic Settings ################################################

#tsdbHost = localhost:4242
### influxHost = metrics.sbrfeeds.com:8086
### influxUsername = admin
### influxPassword = admin
### tsdbVersion = 2.2
#stateFile = /data/bosun.state #No longer used
### ledisDir = /data/ledis_data
### ledisBindAddr = 0.0.0.0:9565
### checkFrequency = 60s
#defaultRunEvery = 1
#smtpUsername = webmaster@sbrforum.com
#smtpPassword = Huro0093
#smtpHost = mail.sbrmail.com:465
### smtpHost = 172.17.0.1:25
#smtpHost = localhost:25
### emailFrom = bosun.alerts@sbrforum.com
### hostname = bosun.sbrfeeds.com
### httpListen = :80

################################################ Templates ################################################


template test-alert-template {
	body = `
	{{$variable := "com.amazonaws.ecs.container-name"}}
	Alert definition:
	
	    <h3>Micros cpu</h3>
	<table>
	<tr><th>Microservice name</th><th>Avg CPU Util</th></tr>
    {{range $ind, $r := .EvalAll .Alert.Vars.avgcpu}}
    {{/* said what */}} 
        <tr><td>{{ index $r.Group "com.amazonaws.ecs.container-name"}} </td>
                    {{if gt .Value 65.0}}
                <td style="color: red;">
                    {{else if gt .Value 50.0}}
                <td style="color: orange;">
                    {{else}}
                <td style="color: green;">{{end}}{{ .Value | pct }}</td></tr>
    {{end}}
    </table>
	`
	subject = {{.Last.Status}}: {{.Alert.Name}} - Alert
}


template micros-split-fullreport {
        body = `
        {{$variable := "com.amazonaws.ecs.container-name"}}
        Alert definition:

            <h3>Micros cpu</h3>
        <table>
        <tr><th>Microservice name</th><th>Avg CPU Util</th></tr>
    {{range $ind, $r := .EvalAll .Alert.Vars.avgcpu}}
    {{/* said what */}}
        <tr><td>{{ index $r.Group "com.amazonaws.ecs.container-name"}} </td>
                    {{if gt .Value 65.0}}
                <td style="color: red;">
                    {{else if gt .Value 50.0}}
                <td style="color: orange;">
                    {{else}}
                <td style="color: green;">{{end}}{{ .Value | pct }}</td></tr>
    {{end}}
    </table>

        <table>
        <tr><th>Microservice name</th><th>Avg MEM Util</th></tr>
    {{range $ind, $r := .EvalAll .Alert.Vars.avgmem}}
    {{/* said what */}}
        <tr><td>{{ index $r.Group "com.amazonaws.ecs.container-name"}} </td>
                    {{if gt .Value 50.0}}
                <td style="color: red;">
                    {{else if gt .Value 25.0}}
                <td style="color: orange;">
                    {{else}}
                <td style="color: green;">{{end}}{{ .Value | pct }}</td></tr>
    {{end}}
    </table>
        `
        subject = {{.Last.Status}}: {{.Alert.Name}} - {{.Tags}} triggered an alarm for CPU or Mem
}

template micros-fullreport {
        body = `
        <!DOCTYPE html>
        <style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        {{$variable := "com.amazonaws.ecs.container-name"}}
        Alert definition:

            <h3>Micros cpu</h3>
    <table>
        <tr><th align="center">Microservice Name</th><th align="center">AvgCpuUtil</th><th align="center">AvgMemUtil</th><th>Mem Usage</th></tr>
    {{range $c := .LeftJoin .Alert.Vars.avgcpu .Alert.Vars.avgmem .Alert.Vars.avgmemtotal}}
        <tr>{{ $cpu := index $c 0}} 
            {{ $mem := index $c 1}}
            {{ $memt := index $c 2}} 
            <td>{{ index $cpu.Group "com.amazonaws.ecs.container-name" }}  </td>
                    {{ if gt $cpu.Value 65.0 }}
                    <td style="color: red;" >
                    {{ else if gt $cpu.Value 50.0 }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $cpu.Value | pct }} </td>
                    
                    {{ if gt $mem.Value 65.0 }}
                    <td style="color: red;">
                    {{ else if gt $mem.Value 50.0 }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $mem.Value | pct }} </td>
                    <td>{{ $memt.Value | bytes }}</td> 
        </tr>            
    {{ end }}                           
                    
    </table>
        `
        subject = {{.Last.Status}}: {{.Alert.Name}} - {{.Tags}} triggered an alarm for CPU or Mem {{ .Incident }}
}

template instances-diskreport {
        body = `
        <!DOCTYPE html>
        <style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        {{$variable := "com.amazonaws.ecs.container-name"}}
        Alert definition:

            <h3>Micros cpu</h3>
    <table>
        <tr><th align="center">Instance</th><th> Envirnment </th><th align="center">Docker data Utillization percent </th><th align="center">Instance disk usage percent</th></tr>
    {{range $c := .LeftJoin .Alert.Vars.availabledockerdata .Alert.Vars.avgtotaldisk}}
        <tr>{{ $availabledockerdata := index $c 0}} 
            {{ $avgtotaldisk := index $c 1}}
            <td>{{ index $availabledockerdata.Group "host" }}  </td>
            <td> {{ $availabledockerdata.Group.env }} </td>
                    {{ if gt $availabledockerdata.Value 85.0 }}
                    <td style="color: red;" >
                    {{ else if gt $availabledockerdata.Value 70.0 }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $availabledockerdata.Value | pct }} </td>
                    
                    {{ if gt $avgtotaldisk.Value 80.0 }}
                    <td style="color: red;">
                    {{ else if gt $avgtotaldisk.Value 60.0 }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $avgtotaldisk.Value | pct }} </td>
                   
        </tr>            
    {{ end }}                           
                    
    </table>
        `
        subject = {{.Last.Status}}: {{.Alert.Name}} - {{.Tags}} triggered an alarm for DISK usage http://bosun.sbrfeeds.com
}

template databses-diskreport {
        body = `
        <!DOCTYPE html>
        <style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        {{$variable := "com.amazonaws.ecs.container-name"}}
        Alert definition:

            <h3>Micros cpu</h3>
    <table>
        <tr><th align="center">Database</th><th align="center">Databases disk Utillization percent</th><th align="center">Path</th></tr>
    {{range $c := .EvalAll .Alert.Vars.avgtotaldisk}}
        <tr>
            <td>{{ index $c.Group "database" }}  </td>
                    {{ if gt .Value 70.0 }}
                    <td style="color: red;" >
                    {{ else if gt .Value 40.0 }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ .Value | pct }} </td>
                    <td> {{ .Group.path }} </td>
        </tr>            
    {{ end }}                           
                    
    </table>
        `
        subject = {{.Last.Status}}: {{.Alert.Name}} - {{.Tags}} triggered an alarm for DISK usage {{ .Eval .Alert.Vars.avgtotaldisk | pct }} On environment = {{ .Group.env }} - visit http://bosun.sbrfeeds.com
}

template startupMicros {
	subject = {{.Last.Status}}: {{.Alert.Name}} /// service {{ .Group.application }} on environment = {{ .Group.env }} restarted multiple times - visit http://bosun.sbrfeeds.com
	body = `
	<style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        Alert definition:

            <h3> Microservices restart </h3>
    <table>
        <tr><th align="center">Service</th><th align="center">Environment</th><th align="center">starts/restarts</th></tr>
    {{range $c := .EvalAll .Alert.Vars.startssum}}
        <tr>
            <td>{{ index $c.Group "application" }} </td>
            <td>{{ index $c.Group "env" }} </td>
            <td>{{ index .Value }} </td>
        </tr>            
    {{ end }}                           
                    
    </table>
`    
}

template MSErrors {
	subject = {{.Last.Status}}: {{.Alert.Name}} count on service {{ .Group.application }} / {{with .Group.api}} {{ . }} {{ else }} {{ .Group.proxy }} {{end}} on environment = {{ .Group.env }} - visit http://bosun.sbrfeeds.com
	body = `
	<style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        Alert definition:

            <h3> Errors </h3>
    <table>
        <tr><th align="center">Application</th><th> Api/Proxy </th><th align="center">Environment</th><th align="center">Count</th></tr>
    {{range $c := .EvalAll .Alert.Vars.errors}}
        <tr>
            <td>{{ index $c.Group "application" }} </td>
            <td>{{ index $c.Group "api" }}{{ index $c.Group "proxy" }} </td>
            <td>{{ index $c.Group "env" }} </td>
            <td>{{ index .Value }} </td>
        </tr>            
    {{ end }}                           
                    
    </table>
`    
}

template latency {
	subject = {{.Last.Status}}: {{.Alert.Name}} count on service {{ .Group.application }} / {{with .Group.api}} {{ . }} {{ else }} {{ .Group.proxy }} {{end}} on environment = production - visit http://bosun.sbrfeeds.com
	body = `
	<style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        Alert definition:

            <h3> Microservice latency </h3>
    <table>
        <tr><th align="center">Application</th><th align="center">API/Proxy</th><th align="center">Latency in Ms</th><th align="center">Limit</th></tr>
       {{range $c := .LeftJoin .Alert.Vars.latency .Alert.Vars.limit }}
        <tr>{{ $latency := index $c 0}}
            {{ $limit := index $c 1}}
            <td>{{ $latency.Group.application }} </td>
            <td>{{ $latency.Group.proxy }} {{ $latency.Group.api }}</td>
             {{ if gt $latency.Value $limit.Value  }}
                    <td style="color: red;" >
                    {{ else if gt $latency.Value $limit.Value  }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $latency.Value }} </td>
                    <td> {{ $limit.Value }} </td>
                   
        </tr>            
    {{ end }}                           
                    
    </table>
`    
}

template count {
	subject = {{.Last.Status}}: {{.Alert.Name}} count on service {{ .Group.application }} / {{ .Group.api}} on environment = production - visit http://bosun.sbrfeeds.com
	body = `
	<style>
        table {border-spacing: 10px; border: 1px solid black;	width: 100%;}
        th {border-spacing: 10px; border: 1px solid black; text-align: center; width: 5%}
        td {border-spacing: 10px; border: 1px solid black; text-align: center;}
        </style>
        Alert definition:

            <h3> Microservice API message error </h3>
    <table>
        <tr><th align="center">Application</th><th align="center">Api</th><th align="center">Count</th><th align="center">Limit</th></tr>
       {{range $c := .LeftJoin .Alert.Vars.latency .Alert.Vars.limit }}
        <tr>{{ $latency := index $c 0}}
            {{ $limit := index $c 1}}
            <td>{{ $latency.Group.application }} </td>
            <td>{{ $latency.Group.proxy }} {{ $latency.Group.api }}</td>
             {{ if gt $latency.Value $limit.Value  }}
                    <td style="color: red;" >
                    {{ else if gt $latency.Value $limit.Value  }}
                    <td style="color: orange;">
                    {{ else }}
                    <td style="color: green;"> {{ end }}{{ $latency.Value }} </td>
                    <td> {{ $limit.Value }} </td>
                   
        </tr>            
    {{ end }}                           
                    
    </table>
`    
}

template default {
	subject = {{.Last.Status}}: {{.Alert.Name}} Default alert /  Values here {{ .Ack }} {{  .Value }}
	body = `<p> This is the default Template!
	<p>Tags:
`
}

template isup {
	subject = {{.Last.Status}}: {{.Alert.Name}} Good thing Bosun is Up! /  {{ .Eval .Alert.Vars.up }} seconds uptime {{ .Ack }} {{  .Value }}
	body = `<p> Bosun is up
	<p>Tags:
`
}

################################################ Notifications ################################################

notification pagerduty {
    post = https://events.pagerduty.com/generic/2010-04-15/create_event.json
    contentType = application/json
    print = true
    body = `{
     "service_key": "7e9da54a8f7d4fac9553420509ee279b",
     "incident_key": {{.|json}},
     "event_type": "trigger",
     "description": {{.|json}},
     "client": "Bosun",
     "client_url": "http://bosun.sbrfeeds.com/"
    }`
}

notification pagerdutytest {
    post = https://events.pagerduty.com/generic/2010-04-15/create_event.json
    contentType = application/json
    print = true
    body = `{
     "service_key": "7e9da54a8f7d4fac9553420509ee279b",
     "incident_key": {{.|json}},
     "event_type": "trigger",
     "description": {{.|json}},
     "client": "Bosun-TEST",
     "client_url": "http://bosun.sbrfeeds.com/"
    }`
}


notification mail {
        print = true
        email = yeris.madrigal@sbrforum.com
        #next = pagerdutytest
}

notification slackfortesting {
	post = https://hooks.slack.com/services/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
	body = {"text": {{.|json}}, "icon_emoji": ":hammer_and_wrench:", "username": "Bosun-test", "channel": "#devopstestalerts"}
	next = mail
	}

notification slack {
        post = https://hooks.slack.com/services/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
        body = {"text": {{.|json}}, "icon_emoji": ":heart_eyes:"}
        }


notification slacknotify {
	post = https://hooks.slack.com/services/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
	body = {"text": {{.|json}}}
        #next = pagerduty
        #timeout = 10m
	}

notification mailto {
	print = true
	email = bosun.notifications@sbrforum.com
}

################################################ Lookups ################################################ 

lookup startups {
	entry env=qa {
		warn = 4
		crit = 1000
	}
	entry env=production {
		warn = 2
		crit = 4
	}
	entry env=uat {
		warn = 4
		crit = 1000
	}

}

lookup errors {
	entry env=qa {
		warn = 1000
		crit = 1000
	}
	entry env=production {
		warn = 1
		crit = 4
	}
	entry env=uat {
		warn = 1000
		crit = 1000
	}

}

lookup latencies {
	entry api=adminUser,application=* {
		warn = 1000
		crit = 1000
	}
	entry api=articles,application=picks_pages_service {
		warn = 1000
		crit = 1000
	}
	entry api=articles,application=picks_admin_service  {
		warn = 1000
		crit = 1000
	}
        entry api=articles,application=articles_service  {
		warn = 1000
		crit = 1000
	}
	entry api=images,application=* {
		warn = 1000
		crit = 1000
	}
	entry api=componentlists,application=* {
		warn = 1000
		crit = 1000
	}
	entry api=components,application=* {
		warn = 1000
		crit = 1000
	}
	entry api=videos,application=* {
		warn = 1000
		crit = 1000
	}
}

################################################ Alerts ################################################


alert microservices {
	template = micros-fullreport
        closeOnNormal = true
        #log = true 
	$metriccpu = influx("main", '''SELECT mean("usage_percent") FROM "docker_container_cpu" WHERE "cluster" = 'microservices' AND "env" = 'production' GROUP BY "com.amazonaws.ecs.container-name" ''', "15m", "", "1m" )
	$metricmem = influx("main", ''' SELECT mean("usage_percent") FROM "docker_container_mem" WHERE "cluster" = 'microservices' AND "env" = 'production' GROUP BY "com.amazonaws.ecs.container-name" ''', "15m", "", "1m" )
        $totalmem = influx("main", ''' SELECT mean("usage") FROM "docker_container_mem" WHERE "cluster" = 'microservices' AND "env" = 'production' GROUP BY "com.amazonaws.ecs.container-name" ''', "15m", "", "1m" )
	$avgcpu = avg($metriccpu)
	$avgmem = avg($metricmem)
        $avgmemtotal = avg($totalmem)
	warn = ($avgcpu > 50) || ($avgmem > 50)
	crit = ($avgcpu > 65) || ($avgmem > 65)
	warnNotification = mailto, slacknotify
        critNotification = mailto, slacknotify, pagerduty
        #critNotification = pagerduty
       
}

alert instancesDisks {
	template = instances-diskreport
	closeOnNormal = true
        #log = true 
        unknownIsNormal = true 
	$totaldockerdata = influx("main", '''SELECT mean("total") FROM "docker_data" WHERE "cluster" = 'microservices' GROUP BY "host", "env" ''', "15m", "", "1m" )
	$useddockerdata = influx("main", '''SELECT mean("used") FROM "docker_data" WHERE "cluster" = 'microservices' GROUP BY "host" ''', "15m", "", "1m" )
        $totaldisk = influx("main", '''SELECT mean("used_percent") FROM "disk" WHERE "cluster" = 'microservices' GROUP BY "host" ''', "15m", "", "1m" )
	$avgtotaldockerdata = avg($totaldockerdata)
	$avguseddockerdata = avg($useddockerdata)
	$avgtotaldisk = avg($totaldisk)
    $availabledockerdata = ($avguseddockerdata / $avgtotaldockerdata) * 100
	warn = ($availabledockerdata > 70) || ($avgtotaldisk > 60)
	crit = ($availabledockerdata > 85) || ($avgtotaldisk > 80)
	
	warnNotification = mailto, slacknotify
    critNotification = mailto, slacknotify, pagerduty
}

alert databasesDisks {
	closeOnNormal = true
	template = databses-diskreport
        #log = true 
        unknownIsNormal = true 
        $totaldisk = influx("main", '''SELECT mean("used_percent") FROM "disk" WHERE "cluster" = 'microservice-dbs' GROUP BY "database", "path", "env" ''', "15m", "", "1m" )
	$avgtotaldisk = avg($totaldisk)
	warn = ($avgtotaldisk > 50)
	crit = ($avgtotaldisk > 75)
	warnNotification = mailto, slacknotify
    critNotification = mailto, slacknotify, pagerduty
}

alert startups-24h {
	closeOnNormal = true
    template = startupMicros
    unknownIsNormal = true 	
    runEvery = 1440
    $starts = influx("main", '''select sum(value) from server_startup where "cluster" = 'microservices' AND "env" = 'production' group by "application", "env" ''', "24h", "", "")
    $startssum = max($starts)
    warn = max($starts) > lookup("startups", "warn")
    crit = max($starts) > 16
    critNotification = mailto
}

alert startups-15m {
	closeOnNormal = true
    template = startupMicros
    $starts = influx("main", '''select sum(value) from server_startup where "cluster" = 'microservices' group by "application", "env" ''', "15m", "", "")
    warn = (max($starts) > lookup("startups", "warn")) || (max($starts) > lookup("startups", "warn"))
    $startssum = max($starts)
    crit = $startssum > lookup("startups", "crit")
    warnNotification = mailto, slacknotify
    critNotification = mailto, slacknotify, pagerduty
}

alert proxy-errors {
	closeOnNormal = true
    template = MSErrors
    unknownIsNormal = true 
    $errors = sum(influx("main", '''select value from proxy_error where "cluster" = 'microservices' AND "env" = 'production' group by "application", "env", "proxy" ''', "15m", "", ""))
    warn = $errors > 5
    warnNotification =  mailto, slacknotify
}

alert websocket-errors {
	closeOnNormal = true
    template = MSErrors
    unknownIsNormal = true 
    $errors = sum(influx("main", '''select value from websocket_error where "cluster" = 'microservices' group by "application", "env", "api" ''', "15m", "", ""))
    warn = $errors > lookup("errors", "warn")
    warnNotification =  mailto, slacknotify
    crit = $errors > lookup("errors", "warn")
    critNotification = mailto, slacknotify, pagerduty
}

alert api-errors {
	closeOnNormal = true
    template = MSErrors
    unknownIsNormal = true 
    $errors = sum(influx("main", '''select value from api_error where "cluster" = 'microservices' group by "application", "env", "api" ''', "15m", "", ""))
    warn = $errors > lookup("errors", "warn")
    warnNotification =  mailto, slacknotify
    crit = $errors > lookup("errors", "warn")
    critNotification = mailto, slacknotify, pagerduty
}

alert api-latency-15m {
	closeOnNormal = true
    template = latency
    unknownIsNormal = true
    unjoinedOk = true
     $historicalLatency = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "90m", "", "")
     $avrlat = avg($historicalLatency)
     $devlat = dev($historicalLatency) * 2.5
     $limit = $avrlat + $devlat
     $latency = avg(influx("main", '''select mean(mean) from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "15m", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     warnNotification =  mailto, slacknotify
    
}

alert proxy-latency-15m {
    template = latency
    unknownIsNormal = true
    closeOnNormal = true
    unjoinedOk = true
     $historicalLatency = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "90m", "", "")
     $avrlat = avg($historicalLatency)
     $devlat = dev($historicalLatency) * 2.5
     $limit = $avrlat + $devlat
     $latency = avg(influx("main", '''select mean(mean) from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "15m", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     warnNotification =  mailto, slacknotify
    
}

alert ws-latency-15m {
	closeOnNormal = true
    template = latency
    unknownIsNormal = true
    unjoinedOk = true
    squelch = application=picks_pages_service ,api=componentlists
    squelch = application=picks_pages_service ,api=components
    squelch = application=picks_admin_service ,api=videos
     $historicalLatency = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "90m", "", "")
     $avrlat = avg($historicalLatency)
     $devlat = dev($historicalLatency) * 2.5
     $limit = $avrlat + $devlat
     $latency = avg(influx("main", '''select mean(mean) from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "15m", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     warnNotification =  mailto, slacknotify
    
}

alert api-latency-1h {
	closeOnNormal = true
    template = latency
    unknownIsNormal = true
    unjoinedOk = true
    runEvery = 5
     $today = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "60m", "", "")
     $day2 =  influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "25h", "24h", "")
     $day3 = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "49h", "48h", "")
     $day4 = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "73h", "72h", "")
     $day5 = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "97h", "96h", "")
     $day6 = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "121h", "120h", "")
     $day7 = influx("main", '''select mean from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "145h", "144h", "")
     $avgdev = ((dev($day2) + dev($day3) + dev($day4) + dev($day5) + dev($day6) + dev($day7)) / 6) * 1.5 
     $avglat = ((avg($day2) + avg($day3) + avg($day4) + avg($day5) + avg($day6) + avg($day7)) / 6)
     #$avrlat = avg($today)
     $devlat = dev($today) * 1.5
     $devlat3 = dev($today) * 3
     $limit = $avglat + $avgdev 
     $limitCrit = $avglat + $devlat3
     $latency = avg(influx("main", '''select mean(mean) from api_latency where "cluster" = 'microservices' AND "env" = 'production' AND "method" = 'GET' group by "application", "api" ''', "1h", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     crit = ($latency > $limitCrit)
     warnNotification =  mailto, slacknotify   
     critNotification = mailto, pagerduty
}

alert proxy-latency-1h {
	closeOnNormal = true
    template = latency
    unknownIsNormal = true
    unjoinedOk = true
    runEvery = 5
     $today = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "60m", "", "")
     $day2 =  influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "25h", "24h", "")
     $day3 = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "49h", "48h", "")
     $day4 = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "73h", "72h", "")
     $day5 = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "97h", "96h", "")
     $day6 = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "121h", "120h", "")
     $day7 = influx("main", '''select mean from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "145h", "144h", "")
     $avgdev = ((dev($day2) + dev($day3) + dev($day4) + dev($day5) + dev($day6) + dev($day7)) / 6) * 1.5 
     $avglat = ((avg($day2) + avg($day3) + avg($day4) + avg($day5) + avg($day6) + avg($day7)) / 6)
     #$avrlat = avg($today)
     $devlat = dev($today) * 1.5
     $devlat3 = dev($today) * 3
     $limit = $avglat + $avgdev
     $limitCrit = $avglat + $devlat3 
     $latency = avg(influx("main", '''select mean(mean) from proxy_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "proxy" ''', "1h", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     crit = ($latency > $limitCrit)
     warnNotification =  mailto, slacknotify
     critNotification = mailto, pagerduty
    
}

alert ws-latency-1h {
	closeOnNormal = true
    template = latency
    unknownIsNormal = true
    unjoinedOk = true
    runEvery = 5
    squelch = application=picks_pages_service ,api=componentlists
    squelch = application=picks_pages_service ,api=components
    squelch = application=picks_admin_service ,api=videos
     $today = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "60m", "", "")
     $day2 =  influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "25h", "24h", "")
     $day3 = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "49h", "48h", "")
     $day4 = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "73h", "72h", "")
     $day5 = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "97h", "96h", "")
     $day6 = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "121h", "120h", "")
     $day7 = influx("main", '''select mean from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "145h", "144h", "")
     $avgdev = ((dev($day2) + dev($day3) + dev($day4) + dev($day5) + dev($day6) + dev($day7)) / 6) * 1.5 
     $avglat = ((avg($day2) + avg($day3) + avg($day4) + avg($day5) + avg($day6) + avg($day7)) / 6)
     #$avrlat = avg($today)
     $devlat = dev($today) * 2.5
     $devlat3 = dev($today) * 4
     $limit = $avglat + $avgdev
     $limitCrit = $avglat + $devlat3
     $latency = avg(influx("main", '''select mean(mean) from websocket_latency where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "1h", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     crit = ($latency > $limitCrit) 
     warnNotification =  mailto, slacknotify
     critNotification = mailto, pagerduty	    
}  

alert api-requests-1h {
	closeOnNormal = true
    template = count
    unknownIsNormal = true
    unjoinedOk = true
    runEvery = 5
     $today = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "60m", "", "")
     $day2 =  influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "25h", "24h", "")
     $day3 = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "49h", "48h", "")
     $day4 = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "73h", "72h", "")
     $day5 = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "97h", "96h", "")
     $day6 = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "121h", "120h", "")
     $day7 = influx("main", '''select count from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "145h", "144h", "")
     $avgdev = ((dev($day2) + dev($day3) + dev($day4) + dev($day5) + dev($day6) + dev($day7)) / 6) * 1.5 
     $avglat = ((avg($day2) + avg($day3) + avg($day4) + avg($day5) + avg($day6) + avg($day7)) / 6)
     #$avrlat = avg($today)
     $devlat = dev($today) * 2.5
     $devlat3 = dev($today) * 4
     $limit = $avglat + $avgdev
     $limitCrit = $avglat + $devlat3
     $latency = avg(influx("main", '''select mean(count) from api_message where "cluster" = 'microservices' AND "env" = 'production' group by "application", "api" ''', "1h", "", "1m"))
     warn = ($latency > $limit) || ($latency > 10000)
     crit = ($latency > $limitCrit) 
     warnNotification = slackfortesting
     critNotification = slackfortesting	    
}  

alert pipelineResources {
	closeOnNormal = true
    template = default
    unknownIsNormal = true
    unjoinedOk = true
    $cpuUsage = influx("main", '''select usage_system+usage_user from cpu where "cluster"='pipelinedownloader' AND "env"='production' group by "host" ''', "1h", "", "")
    $usedMem = influx("main", '''select used_percent from mem where "cluster"='pipelinedownloader' AND "env"='production' group by "host" ''', "1h", "", "")
    warn = avg($cpuUsage) > 20 || avg($usedMem) > 30
    warnNotification = slackfortesting
}

alert pipelineImpoResources {
	closeOnNormal = true
    template = default
    unknownIsNormal = true
    unjoinedOk = true
    $cpuUsage = influx("main", '''select usage_system+usage_user from cpu where "cluster"='pipelineimporter' AND "env"='production' group by "host" ''', "1h", "", "")
    $usedMem = influx("main", '''select used_percent from mem where "cluster"='pipelineimporter' AND "env"='production' group by "host" ''', "1h", "", "")
    warn = avg($cpuUsage) > 20 || avg($usedMem) > 30
    warnNotification = slackfortesting
}

alert pipelinedownErrors {
    closeOnNormal = true
    template = default
    unknownIsNormal = true
    unjoinedOk = true
    $errors = influx("main", '''select value from processor_error where "cluster"='pipelinedownloader' AND "env"='production' group by "host" ''', "1h", "", "")
    warn = max($errors) > 20 
    warnNotification = slackfortesting
}

alert pipelineImpoErrors {
    closeOnNormal = true
    template = default
    unknownIsNormal = true
    unjoinedOk = true
    $errors = influx("main", '''select value from processor_error where "cluster"='pipelineimporter' AND "env"='production' group by "host" ''', "1h", "", "")
    warn = max($errors) > 20 
    warnNotification = slackfortesting
}

#alert Test {
# 	template = test-alert-template
#        log = true
# 	$metriccpu = influx("main", '''SELECT mean("usage_percent") FROM "docker_container_cpu" WHERE "cluster" = 'microservices' AND "env" = 'production' GROUP BY "com.amazonaws.ecs.container-name" ''', "15m", "", "1m" )
# 	$avgcpu = avg($metriccpu)
 	#crit = $avgcpu > 13
#        crit = 1
# 	critNotification = mailto, slackfortesting
#}
